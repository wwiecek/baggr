---
title: "Aggregating Average Treatment Effects with Baggr"
author: "Rachael Meager, Witold Wiecek"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{baggr}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: baggr.bib
---
  
```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>")
library(baggr)
library(ggplot2)
baggr_schools <- baggr(schools, model = "rubin", pooling = "partial")
baggr_plot(baggr_schools)
baggr_compare(schools)
my_baggr_plot <- baggr_compare(schools)

```



_This vignette is - like the package itself - still under construction. We encourage your feedback._

_baggr_ (pronounced "bagger" or "badger" and short for Bayesian Aggregator) is a package for aggregating evidence on causal effects measured in several separate and different instances. These instances may be different studies, groups, locations or "sites" however conceptualised. We refer to these separate pieces of evidence as "groups" for the remainder of this vignette When each group is a study, the model is that of _meta-analysis_, but aggregation of evidence is not limited to this case.

One of the most basic objects of interest is the _[average treatment effect](http://www.fsb.muohio.edu/lij14/420_paper_Rubin74.pdf)_, the difference in the mean outcome in treatment and control groups; for more information see work by @rubin_estimating_1974. In meta-analysis we are often interested in the average of this average effect across groups, estimated using all the evidence from all the groups. Consider the case where the evidence in each study or group is generated by comparing the outcomes of treatment and control samples in a randomized experiment. We will ignore any covariate information at the individual or group level for now.

Consider some outcome of interest $y_{ik}$ such as consumption, income or health outcomes for a household or individual $i = 1,2,...N_k$ in study group $k = 1,2....K$. Let $Y_k$ denote the $N_k$-length vector of observed outcomes from group $k$. Denote the binary indicator of treatment status by $T_{ik}$, and denote by $T_k$ the $N_k$-length vector of all treatment status indicators from group $k$. 

Suppose that $y_{ik}$ varies randomly around its mean $\mu_k + \tau_k T_i$. In this setting $\tau_k$ is the treatment effect in group $k$. The random variation in $y_{ik}$ may be the result of sampling variation or measurement error, as in the @rubin_estimation_1981 model, or it may be the result of unmodeled heterogeneity or uncertainty in outcomes for individuals within the group. Allow the variance of the outcome variable $y_{ik}$ to vary across sites, so $\sigma_{y_k}^2$ may differ across $k$. 



## Data inputs: reported effects or full individual-level data sets

For average effects aggregation, _baggr_ allows 3 types of data inputs. The user may supply, within a data frame environment, any of the following:

1. A set of estimated treatment effects $\{\hat{\tau_k}\}_{k=1}^{K}$ and their standard errors $\{\hat{se_k}\}_{k=1}^{K}$ from each study. This should be formatted as two column vectors of length $K$ within the data frame, where $\hat{\tau_k}$ is the $k$-th entry of the treatment effect vector and  $\hat{se_k}$ is the $k$-th entry of the standard errors vector. Columns should be names "tau" and "se". 

2. A set of control group means and estimated treatment effects $\{\hat{\mu_k},\hat{\tau_k}\}_{k=1}^{K}$, as well as the standard errors for both $\{\hat{se}_{\mu k}, \hat{se}_{\tau k}\}_{k=1}^{K}$, for each study site This should be formatted as four vectors of length $K$ within the data frame, analogous to the above. Columns should be names "mu", "tau", "se.mu", "se.tau".

3. The full data sets from all the original studies $\{Y_k, T_k\}_{k=1}^{K}$. This should be formatted as three vectors of length $\sum_{k=1}^K N_{k}$, which we recommend naming "outcome", "treatment", "group" (for site indicators), but the names can also be specified when calling `baggr()` function.

As an example of an individual-level data set we include in data frames `microcredit` and `microcredit_simplified`.



## ATE aggregation models in _baggr_

_baggr_ currently contains two different models suitable for aggregating sets of average treatment effects. Consider first the evidence aggregation model from @rubin_estimation_1981, discussed extensively in Chapter 5 of @gelman_bayesian_2013; the model consists of a hierarchical likelihood as follows:

\begin{equation}
\begin{aligned}
\hat{\tau_k} &\sim N(\tau_k, \hat{se_k}^2) \; \forall \; k \\
\tau_k &\sim N(\tau, \sigma_{\tau}^2) \; \forall \; k .
\end{aligned}
\label{rubin model}
\end{equation}

The motivation for this model structure is discussed in detail in the sources above and in @meager_aggregating_2019-1. To complete the Bayesian model, we now need priors. _baggr_ has a set of default priors for each model as well as allowing the user to specify her own priors if desired. In the Rubin model, _baggr_'s default priors on the hyper parameters are as follows: for $\tau$, the prior is Normal with mean 0 and variance 1000. This is a very weak prior which does little regularization as a default, centered at zero following the basic philosophical approach that causal effects should not be thought of as large unless data contains evidence to the contrary (a "hand-wavey" form of Occam's Razor). For $\sigma_{\tau}$ the prior is Uniform on an interval from zero to 10 times the simple or naive variance estimator of the vector $\{\hat{\tau_k}\}_{k=1}^{K}$ generated by the R command var().

In case you also have data on the control groups' mean outcomes and the uncertainty on those, it would make sense to augment the @rubin_estimation_1981 model to incorporate that information. Following @meager_aggregating_2019-1, if one has access to the estimated control means  $\{\hat{\mu_k}\}^K_{k=1}$ and their standard errors $\{\hat{se}_{\mu k}\}^K_{k=1}$, one can fit a jointly Normal model on the pairs $\{\hat{\mu_k},\hat{\tau_k}\}_{k=1}^{K}$. _baggr_ implements the model from @meager_aggregating_2019-1 which it calls the "mutau" model, like so:

\begin{equation}
\begin{aligned}
\hat{\tau_k} &\sim N(\tau_k, \hat{se_{\tau k}}^2) \; \forall \; k \\
\hat{\mu_k} &\sim N(\mu_k, \hat{se_{\mu k}}^2) \; \forall \; k \\
\left( \begin{array}{c}
\mu_{k}\\
\tau_{k}
\end{array} \right) 
&\sim
N\left( \left(
\begin{array}{c}
\mu\\
\tau
\end{array} \right), V \right) \; \text{where} \;V = \left[ \begin{array}{cc} \sigma^2_{\mu} & \sigma_{\tau\mu} \\ \sigma_{\tau\mu} & \sigma_{\tau}^2 \end{array} \right]\forall \; k. \\
\end{aligned}
\label{full data model}
\end{equation}

If you have only few groups, the priors on $V$ will need to be relatively strong to avoid overfitting. See @meager_aggregating_2019-1 for more discussion of this issue in particular, or see the [Stan Manual on hierarchical priors](https://mc-stan.org/docs/2_18/stan-users-guide/multivariate-hierarchical-priors-section.html). Currently $V$ is decomposed into a correlation matrix $\Omega$, which receives an LKJCorr(3) prior regularizing it towards independence, and a scale parameter $\theta$ which receives a Cauchy(0,10) prior. This will be something the user can change in later versions of _baggr_.  The $mu$ and $\tau$ parameters have a joint gaussian prior which the user can specify, but which by default is centered at 0. The centering can be changed to any vector of length 2 by passing this vector to _baggr_ labelled as "prior_tau_mean"). The default covariance matrix of this prior is independent with variance $1000^2$, but the user can pass any prior covariance matrix to _baggr_ labelled as "prior_tau_scale". 
```{r}
```


## Models, their inputs, likelihood and priors: a summary table

<!-- This is a mess to edit, sorry. But it presents nicely in Markdown -->

|Model               | Data frame input columns       | Level-1 likelihood                              | Level-2 likelihood                      | Priors   |
|--------------------|--------------------------------|-------------------------------------------------|-----------------------------------------|----------|
| "Rubin"            | `tau` and `se`                 | $\hat{\tau_k} \sim N(\tau_k, \hat{se_k}^2)$     | $\tau_k \sim N(\tau, \sigma_{\tau}^2)$  | $\tau \sim \mathcal{N}(0, \sigma^2)$, $\sigma_{\tau} \sim \mathcal{U}(0, u)$  | 
| "$\mu$ and $\tau$" | `tau`, `mu`, `se.tau`, `se.mu` | $\hat{\tau_k} \sim N(\tau_k, \hat{se_{\tau,k}}^2)$, $\hat{\mu_k} \sim N(\mu_k, \hat{se_{\mu,k}}^2)$  | $\pmatrix{\mu_k \\ \tau_k} \sim N(\pmatrix{\mu \\ \tau}, V)$ | $V = \theta \Omega \theta'$ where $\theta \sim Cauchy(0,10)$ and $\Omega \sim LKJCorr(3)$. $\pmatrix{\mu \\ \tau} \sim N(0,\Xi )$ |
| Full data          | outcome, treatment, group  | Same as for "$\mu$ and $\tau$" | Same as for "$\mu$ and $\tau$" | Same as for "$\mu$ and $\tau$" |
| Quantiles          | outcome, treatment, group  | See Meager (2019)    | See Meager (2019)          | See Meager (2019)  |



## Running the Rubin Model in _baggr_

To demonstrate the Rubin model in _baggr_, consider the 8 schools example from Rubin (1981). In this dataset, 8 schools in the United States performed similar randomized experiments to estimate the causal effect of an SAT tutoring program on learning outcomes. Reported  treatment effects and their standard errors are included in  _baggr_ as a data frame:

```{r}
schools
```


To fit this model in Stan (having followed the installation instructions) we can follow ["How to use rstan" example](https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started#how-to-use-rstan). To fit the model in _baggr_ (also having followed the installation instructions and loaded the package): 

```{r eval=FALSE}
baggr_schools <- baggr(schools, model = "rubin", pooling = "partial")
```

This creates a `baggr` class object, and you can access the underlying `stanfit` object by calling `baggr_schools$fit`. If you don't change the default priors, then _baggr_ will print a message informing you of the priors it has chosen. 

Printing `baggr_schools` returns a summary of the posterior inference. First _baggr_ records the model type and the pooling regime chosen by the user or implemented by default. Second, _baggr_ returns inference on the aggregate treatment effect $\tau$ by reporting its posterior mean and 95\% credible interval, and similar inference on the hypervariance $\sigma^2_{\tau}$. Lastly it prints the "updated" inference on each of the groups' treatment effects, displaying their new posterior means, standard deviations and pooling factors (see below).

```{r}
print(baggr_schools)
```

This is quite similar to the output from the version of the model suggested in ["How to use rstan"]((https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started)) tutorial, the small difference probably arising from the different default priors.

As discussed above, it is possible for the user to override the default priors and specify her own priors. The first parameter you can change is the upper bound of the uniform prior on $\sigma_{\tau}$, called `"prior_upper_sigma_tau"`, the second is the mean of the prior on $\tau$ itself called `"prior_tau_mean"`, the third is the scale (standard deviation) of the prior on $\tau$ itself called `"prior_tau_scale"`. Here I have changed all three as an example (at this stage in _baggr_ if you want to alter one you must provide the full vector): 
```{r eval=FALSE}
baggr(schools, "rubin", prior = c("prior_upper_sigma_tau" = 10000, 
                                  "prior_tau_mean" = -10, 
                                  "prior_tau_scale" = 100))
baggr_schools
```

<!-- #[WORKING SECTION Suppose you have the full individual-level dataset for all groups (case 3 above) but still wish to run the Rubin model: _baggr_ can do this automatically, you do not need to manually estimate the group-specific effects and standard errors yourself. To see how it works, check out the microcredit dataset analysed in Meager (2019) which is stored in _baggr_ as the data frame "microcredit". Have a look at the tail of the data frame, which tells you that these households are from the "Tarozzi" et al study group (the Ethiopia trial), for which we have expenditures, revenue and profit data, as well as the treatment indicator. -->
<!-- # ```{r} -->
<!-- # tail(microcredit) -->
<!-- # ``` -->
<!-- # _baggr_ will only understand the 3 types of formatting described above, and while we have already stacked this dataset, we now need to choose a single outcome to focus on.  ] -->

Currently, all our models specify Gaussian effects distributions across groups. This is generally appropriate as a first pass at the problem (see Rubin 1981, Gelman et al 2004 and McCollough and Nuehaus 2011 for more) _except_ if the distribution is known to be asymmetric for scientific reasons. For example, if you are working with risk ratios or odds ratios these statistics cannot be negative and the chosen hyperdistribution should typically reflect that. However, in many cases it is possible and indeed standard to maintain the Gaussian assumption on a transform of the object: for example, you can safely fit the Rubin model to the logarithm of the risk ratios or odds ratios. While bearing in mind that log transforms obscure inherent dependences between means and variances in the raw scale, this is still much better than applying a Gaussian to the raw object itself. 

## Understanding and criticising _baggr_ model performance

_Baggr_ models are run in Stan, and the fit and results need to be checked, understood and criticised as you would any stan model or indeed any MCMC model fitting exercise. **You must pay attention to printed warnings about the Rhat criterion: if you see a warning that Rhat statistic exceeds 1.05 for any parameter, you MUST NOT use the results for inference.** This warning means the MCMC chains have not converged, and it is exceedingly unlikely that the "posterior inference" printed out corresponds to anything close to the true posterior implied by your model and data. **If you use results from which the Rhat statistic exceeds 1.05 YOUR INFERENCE WILL BE WRONG.**

If you see this warning, try re-running the model with the option `"iter"` set to a large number such as 10,000, as below. It is also good practice to run many chains, such as 8 rather than the default 4, to have a greater chance to detect pathological MCMC behaviour. You do this by passing _baggr_ the stan arguments "iter = 10000" and "chains = 8", like so:

```{r eval=FALSE}
baggr_schools <- baggr(schools, model = "rubin", pooling = "partial", iter = 10000, chains = 8)
```

Other warnings you may see involve "divergent transitions". While not as serious as high Rhat, this can signal problems with the model. As the stan message that you will see suggests, try adjusting `adapt_delta` argument above 0.8, e.g. to 0.99. You cannot pass this parameter directly to _stan_ and thus you cannot pass it directly to baggr, so instead you must pass the argument `control = list(adapt_delta = 0.99)`. 


## Measuring "pooling"

It is often useful to measure the extent to which the hierarchical model is "pooling" or sharing information across the $K$ groups in the process of aggregation. Baggr automatically computes such a metric, and as one can see above, printing a baggr object displays a column called "pooling". This column contains the classical pooling metric that describes the extent to which each of the group effects is "shrunk" towards their common mean in the process of aggregating information across groups. While there are many different measures of pooling, and the appropriate metric depends on the specific research question, baggr computes by default the @gelman_bayesian_2006 metric, which delivers the percentage of total variation in $\hat{\tau_k}$ around $\tau$ which is attributed to sampling variation within group $k$:
\begin{equation}
\omega_{\tau_k} = \frac{\hat{se}^2_{k}}{\hat{se}^2_{k} + \sigma^2_{\tau}}.
\end{equation}
Baggr uses the posterior mean of $\sigma^2_{\tau}$ to compute this metric (capacity to print bounds is coming soon). 

One can interpret the metric as follows: if this pooling metric is large and approaching 1, the analyst gains a lot by pooling information across groups; if this is small and approaching 0, one gains little from the aggregated analysis relative to inference on each group separately ("no pooling"). For further discussion see @gelman_bayesian_2006, Gelman and Pardoe (2006) or Meager (2019). 






## Plotting and model comparison in _baggr_

A fundamental step to understanding the model is to plot the posterior distributions. _baggr_ has several automatic plot functions which you can access by calling `baggr_plot()`; these visuals are based on `bayesplot` package. 
Plotting functions always take `baggr` class object as their first argument. By default, means and 95\% posterior intervals of the effects _in each group_ are shown. Extra options are available, such as whether to order the results by effect size. For the 8 schools Rubin model we have

```{r fig.width=4}
baggr_plot(baggr_schools, order = FALSE)
```

The second step to understanding the model is to compare it to other models we could have fit: this can be done automatically in _baggr_ using the command `baggr_compare`. The default Rubin model (which we have selected explicitly above) is that of partial pooling. When using `baggr_compare` without any extra arguments, full pooling, no pooling and partial pooling versions of the model will be fit:

```{r eval=FALSE}
baggr_compare(schools)
```

(We will show the output of this function below.) Different comparisons, e.g. of models using different priors, are also possible. 

__[Here we will include a comparison of priors for 8 schools model]__

The `baggr_compare` command also produces an automatic comparison plot made by calling `ggplot2` package. Because the output object of baggr_compare is a `ggplot` object you can edit it further yourself and built on it as you would any `ggplot` object. For example, the default title for the plot is just "mean", so here I've changed it to be more descriptive:

```{r, echo=FALSE, eval = TRUE, include = FALSE}
my_baggr_plot <- baggr_compare(schools)
```

```{r, echo=TRUE, eval = FALSE}
my_baggr_plot <- baggr_compare(schools)
```

```{r fig.width=7, fig.height=4}
my_baggr_plot$plot + ggtitle("8 schools: model comparison")
```



## Cross-validation in _baggr_

_Baggr_ has built-in, automated leave-one-out cross validation for its models, where the "one" always refers to one group. This naturally corresponds to the question of how much any one group has contributed to the overall inference. Therefore, if you have $K$ groups, using the `loocv()` will run your model of choice $K$ times. Be aware that this may take a while even for simple models. (You should see a progress bar in your terminal window.) The `loocv()` function takes in the same arguments as `baggr()`, plus an option (`return_models`) for whether to return all the models or just the summary statistics. For the 8 schools example we can do

```{r loocv, eval = FALSE}
loocv_res <- loocv(schools, return_models = FALSE, "rubin", pooling = "partial")
```

```{r echo = FALSE, include = FALSE}
#this is ugly but effective way to stop output from loocv getting printed
loocv_res <- loocv(schools, return_models = FALSE, "rubin", pooling = "partial")
```

```{r}
loocv_res
```

The main output is $-2$ times the log predictive density (_lpd_) averaged over 8 models, which corresponds to the Watanabe-Aikake Information Criterion. A WAIC value closer to zero (i.e. a smaller number in magnitude) means a better fit. 

More data are stored in `loocv()` output, and can be accessed via `attributes()`, e.g. the mean treatment effects, their variability and _lpd_ for each model that are stored in the attribute `df`:

```{r}
names(attributes(loocv_res))
attr(loocv_res, "df")
```

This data frame can then be used to examine or compute the variation in the inference on $\tau$ in the absence of each group. If the user is interested in manually checking the consequences of excluding a particular group or set of groups, this is also possible in _baggr_ using subsetting. For example, suppose that we want to run the Rubin model on school groups 1-7 and predict the effect in the 8th school. The code below shows how you can specify a subset of the dataframe as your "data" argument, and then designate another subset as the "testing" holdout set by assigning it to the argument "test_data" in the baggr command. Here we have done it for both partial and full pooling:

```{r, echo = FALSE, include = FALSE}
fit1 <- baggr(data = schools[1:7,], test_data = schools[8,], model = "rubin", pooling = "partial")
fit2 <- baggr(data = schools[1:7,], test_data = schools[8,], model = "rubin", pooling = "full")
```

```{r, echo = TRUE, eval = FALSE}
fit1 <- baggr(data = schools[1:7,], test_data = schools[8,], model = "rubin", pooling = "partial")
fit2 <- baggr(data = schools[1:7,], test_data = schools[8,], model = "rubin", pooling = "full")
```
We can now ordinally compare the performance of the two models using the mean log predictive density. This itself is a density as the name suggests so we will compute the log expected value of this density: here, as before, a number closer to zero is better. In this case the full pooling model actually does slightly better:
```{r}
fit1$mean_lpd
fit2$mean_lpd
```

## References

