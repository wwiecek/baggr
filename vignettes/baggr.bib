@inproceedings{gelman2020slamming,
    title={Slamming the sham: A Bayesian model for adaptive adjustment with noisy control data},
    author={Gelman, Andrew and V{\'{a}}k{\'{a}}r, Matthijs},
    year={2020}
}

@article{gelman_understanding_2014,
  title = {Understanding Predictive Information Criteria for {{Bayesian}} Models},
  volume = {24},
  issn = {0960-3174, 1573-1375},
  abstract = {We review the Akaike, deviance, and Watanabe-Akaike information criteria from a Bayesian perspective, where the goal is to estimate expected out-of-sample-prediction error using a biascorrected adjustment of within-sample error. We focus on the choices involved in setting up these measures, and we compare them in three simple examples, one theoretical and two applied. The contribution of this review is to put all these information criteria into a Bayesian predictive context and to better understand, through small examples, how these methods can apply in practice.},
  language = {en},
  number = {6},
  journal = {Statistics and Computing},
  doi = {10.1007/s11222-013-9416-2},
  author = {Gelman, Andrew and Hwang, Jessica and Vehtari, Aki},
  month = nov,
  year = {2014},
  pages = {997-1016},
  file = {C\:\\Users\\wwiecek.CERTARA\\Zotero\\storage\\KDSC9Z5I\\Gelman et al. - 2014 - Understanding predictive information criteria for .pdf},
  note = {00642}
}

@book{gelman_bayesian_2013,
  title = {Bayesian {{Data Analysis}}},
  isbn = {978-1-4398-9820-8},
  abstract = {Winner of the 2016 De Groot Prize from the International Society for Bayesian Analysis Now in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied approach to analysis using up-to-date Bayesian methods. The authors\textemdash{}all leaders in the statistics community\textemdash{}introduce basic concepts from a data-analytic perspective before presenting advanced methods. Throughout the text, numerous worked examples drawn from real applications and research emphasize the use of Bayesian inference in practice. New to the Third Edition   Four new chapters on nonparametric modeling Coverage of weakly informative priors and boundary-avoiding priors Updated discussion of cross-validation and predictive information criteria Improved convergence monitoring and effective sample size calculations for iterative simulation Presentations of Hamiltonian Monte Carlo, variational Bayes, and expectation propagation New and revised software code   The book can be used in three different ways. For undergraduate students, it introduces Bayesian inference starting from first principles. For graduate students, the text presents effective current approaches to Bayesian modeling and computation in statistics and related fields. For researchers, it provides an assortment of Bayesian methods in applied statistics. Additional materials, including data sets used in the examples, solutions to selected exercises, and software instructions, are available on the book's web page.},
  language = {en},
  publisher = {{CRC Press}},
  author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
  month = nov,
  year = {2013},
  keywords = {Mathematics / Probability \& Statistics / General,Psychology / Research \& Methodology}
}

@article{rubin_estimation_1981,
  title = {Estimation in {{Parallel Randomized Experiments}}},
  volume = {6},
  issn = {0362-9791},
  abstract = {[Many studies comparing new treatments to standard treatments consist of parallel randomized experiments. In the example considered here, randomized experiments were conducted in eight schools to determine the effectiveness of special coaching programs for the SAT. The purpose here is to illustrate Bayesian and empirical Bayesian techniques that can be used to help summarize the evidence in such data about differences among treatments, thereby obtaining improved estimates of the treatment effect in each experiment, including the one having the largest observed effect. Three main tools are illustrated: 1) graphical techniques for displaying sensitivity within an empirical Bayes framework, 2) simple simulation techniques for generating Bayesian posterior distributions of individual effects and the largest effect, and 3) methods for monitoring the adequacy of the Bayesian model specification by simulating the posterior predictive distribution in hypothetical replications of the same treatments in the same eight schools.]},
  number = {4},
  journal = {Journal of Educational Statistics},
  author = {Rubin, Donald B.},
  year = {1981},
  pages = {377-401}
}

@article{meager_aggregating_2019-1,
  title = {Aggregating {{Distributional Treatment Effects}}: {{A Bayesian Hierarchical Analysis}} of the {{Microcredit Literature}}},
  shorttitle = {Aggregating {{Distributional Treatment Effects}}},
  abstract = {This paper develops methods to aggregate evidence on distributional treatment effects from multiple studies conducted in different settings, and applies them to the microcredit literature. Several randomized trials of expanding access to microcredit found substantial effects on the tails of household outcome distributions, but the extent to which these findings generalize to future settings was not known. Aggregating the evidence on sets of quantile effects poses additional challenges relative to average effects because distributional effects must imply monotonic quantiles and pass information across quantiles. Using a Bayesian hierarchical framework, I develop new models to aggregate distributional effects and assess their generalizability. For continuous outcome variables, the methodological challenges are addressed by applying transforms to the unknown parameters. For partially discrete variables such as business profits, I use contextual economic knowledge to build tailored parametric aggregation models. I find generalizable evidence that microcredit has negligible impact on the distribution of various household outcomes below the 75th percentile, but above this point there is no generalizable prediction. Thus, while microcredit typically does not lead to worse outcomes at the group level, there is no generalizable evidence on whether it improves group outcomes. Households with previous business experience account for the majority of the impact and see large increases in the right tail of the consumption distribution.},
  language = {en},
  doi = {10.31222/osf.io/7tkvm},
  author = {Meager, Rachael},
  year = {2019}
}

@article{rubin_estimating_1974,
  title = {Estimating {{Causal Effects}} of {{Treatments}} in {{Randomized}} and {{Nonrandomized Studies}}},
  copyright = {closed access},
  issn = {0022-0663},
  abstract = {Presents a discussion of matching, randomization, random sampling, and other methods of controlling extraneous variation. The objective was to specify the benefits of randomization in estimating causal effects of treatments. It is concluded that randomization should be employed whenever possible but that the use of carefully controlled nonrandomized data to estimate causal effects is a reasonable and necessary procedure in many cases.},
  language = {en\_US},
  journal = {Journal of Educational Psychology},
  doi = {10.1037/h0037350},
  author = {Rubin, Donald B.},
  year = {1974}
}

@article{firpo_efficient_2007,
  title = {Efficient {{Semiparametric Estimation}} of {{Quantile Treatment Effects}}},
  volume = {75},
  issn = {0012-9682},
  abstract = {This paper develops estimators for quantile treatment effects under the identifying restriction that selection to treatment is based on observable characteristics. Identification is achieved without requiring computation of the conditional quantiles of the potential outcomes. Instead, the identification results for the marginal quantiles lead to an estimation procedure for the quantile treatment effect parameters that has two steps: nonparametric estimation of the propensity score and computation of the difference between the solutions of two separate minimization problems. Root-N consistency, asymptotic normality, and achievement of the semiparametric efficiency bound are shown for that estimator. A consistent estimation procedure for the variance is also presented. Finally, the method developed here is applied to evaluation of a job training program and to a Monte Carlo exercise. Results from the empirical application indicate that the method works relatively well even for a data set with limited overlap between treated and controls in the support of covariates. The Monte Carlo study shows that, for a relatively small sample size, the method produces estimates with good precision and low bias, especially for middle quantiles.},
  number = {1},
  journal = {Econometrica},
  author = {Firpo, Sergio},
  year = {2007},
  pages = {259-276}
}

@article{mcculloch_misspecifying_2011,
  title = {Misspecifying the {{Shape}} of a {{Random Effects Distribution}}: {{Why Getting It Wrong May Not Matter}}},
  volume = {26},
  issn = {0883-4237, 2168-8745},
  language = {EN},
  number = {3},
  journal = {Statistical Science},
  author = {McCulloch, Charles E. and Neuhaus, John M.},
  month = aug,
  year = {2011},
  keywords = {Maximum likelihood,mixed models,parametric modeling},
  pages = {388-402}
}



@article{yusuf_beta_1985,
  title = {Beta Blockade during and after Myocardial Infarction: An Overview of the Randomized Trials},
  volume = {27},
  issn = {0033-0620},
  shorttitle = {Beta Blockade during and after Myocardial Infarction},
  language = {eng},
  number = {5},
  journal = {Progress in Cardiovascular Diseases},
  doi = {10.1016/s0033-0620(85)80003-7},
  author = {Yusuf, S. and Peto, R. and Lewis, J. and Collins, R. and Sleight, P.},
  year = {1985},
  keywords = {Adrenergic beta-Antagonists,Arrhythmias; Cardiac,Clinical Trials as Topic,Coronary Disease,Humans,Long-Term Care,Methods,Myocardial Infarction,Random Allocation},
  pages = {335-371},
  pmid = {2858114}
}

@article{bradburn_much_2007,
  title = {Much Ado about Nothing: A Comparison of the Performance of Meta-Analytical Methods with Rare Events},
  volume = {26},
  issn = {0277-6715},
  shorttitle = {Much Ado about Nothing},
  language = {eng},
  number = {1},
  journal = {Statistics in Medicine},
  doi = {10.1002/sim.2528},
  author = {Bradburn, Michael J. and Deeks, Jonathan J. and Berlin, Jesse A. and Russell Localio, A.},
  month = jan,
  year = {2007},
  keywords = {Female,Humans,Randomized Controlled Trials as Topic,Databases; Factual,Infant; Newborn,Pregnancy,Computer Simulation,Confidence Intervals,Biometry,Meta-Analysis as Topic,Infant Mortality,Logistic Models,Odds Ratio,Analysis of Variance,Drug-Related Side Effects and Adverse Reactions,Infant; Postmature,Mental Disorders,Risk,Safety},
  pages = {53-77},
  file = {C\:\\Users\\wwiecek.CERTARA\\Zotero\\storage\\B4CYDQJB\\Bradburn et al. - 2007 - Much ado about nothing a comparison of the perfor.pdf},
  pmid = {16596572}
}


@article{gelman_bayesian_2006,
  title = {Bayesian {{Measures}} of {{Explained Variance}} and {{Pooling}} in {{Multilevel}} ({{Hierarchical}}) {{Models}}},
  volume = {48},
  issn = {0040-1706, 1537-2723},
  language = {en},
  number = {2},
  journal = {Technometrics},
  doi = {10.1198/004017005000000517},
  author = {Gelman, Andrew and Pardoe, Iain},
  month = may,
  year = {2006},
  pages = {241-251},
  note = {00000}
}

@article{von_hippel_heterogeneity_2015,
  title = {The Heterogeneity Statistic {{I2}} Can Be Biased in Small Meta-Analyses},
  volume = {15},
  issn = {1471-2288},
  journal = {BMC Medical Research Methodology},
  doi = {10.1186/s12874-015-0024-z},
  author = {{von Hippel}, Paul T},
  month = apr,
  year = {2015},
  pmid = {25880989},
  pmcid = {PMC4410499}
}

@article{higgins_measuring_2003-2,
  title = {Measuring Inconsistency in Meta-Analyses},
  volume = {327},
  issn = {0959-8138},
  abstract = {Cochrane Reviews have recently started including the quantity I2 to help readers assess the consistency of the results of studies in meta-analyses. What does this new quantity mean, and why is assessment of heterogeneity so important to clinical practice?},
  number = {7414},
  journal = {BMJ : British Medical Journal},
  author = {Higgins, Julian P T and Thompson, Simon G and Deeks, Jonathan J and Altman, Douglas G},
  month = sep,
  year = {2003},
  pages = {557-560},
  pmid = {12958120},
  pmcid = {PMC192859}
}


@article{baker_understanding_2009,
	title = {Understanding heterogeneity in meta-analysis: the role of meta-regression},
	volume = {63},
	issn = {1742-1241},
	shorttitle = {Understanding heterogeneity in meta-analysis},
	doi = {10.1111/j.1742-1241.2009.02168.x},
	abstract = {},
	language = {eng},
	number = {10},
	journal = {International Journal of Clinical Practice},
	author = {Baker, W. L. and White, C. Michael and Cappelleri, J. C. and Kluger, J. and Coleman, C. I. and {Health Outcomes, Policy, and Economics (HOPE) Collaborative Group}},
	month = oct,
	year = {2009},
	pmid = {19769699},
	keywords = {Bias, Data Display, Data Interpretation, Statistical, Meta-Analysis as Topic, Random Allocation, Regression Analysis},
	pages = {1426--1434}
}


@article{deeks_issues_2002,
	title = {Issues in the selection of a summary statistic for meta-analysis of clinical trials with binary outcomes},
	volume = {21},
	issn = {0277-6715},
	doi = {10.1002/sim.1188},
	language = {eng},
	number = {11},
	journal = {Statistics in Medicine},
	author = {Deeks, Jonathan J.},
	month = jun,
	year = {2002},
	pmid = {12111921},
	keywords = {Humans, Immunization, Clinical Trials as Topic, Meta-Analysis as Topic, Odds Ratio, Pain, Anti-Inflammatory Agents, Non-Steroidal, Aspirin, Dyspepsia, Helicobacter pylori, Meningitis, Polysaccharides, Bacterial},
	pages = {1575--1600},
	file = {Deeks - 2002 - Issues in the selection of a summary statistic for.pdf:C\:\\Users\\witol\\Zotero\\storage\\67AC3YH3\\Deeks - 2002 - Issues in the selection of a summary statistic for.pdf:application/pdf}
}


@article{labbe_meta-analysis_1987,
	title = {Meta-analysis in clinical research},
	volume = {107},
	issn = {0003-4819},
	doi = {10.7326/0003-4819-107-2-224},
	abstract = {Meta-analysis is the process of combining study results that can be used to draw conclusions about therapeutic effectiveness or to plan new studies. We review important design and statistical issues of this process. The design issues include protocol development, objectives, literature search, publication bias, measures of study outcomes, and quality of the data. The statistical issues include consistency (homogeneity) of study outcomes, and techniques for pooling results from several studies. Guidelines are provided to assess the quality of meta-analyses based on our discussion of the design and statistical issues. Limitations and areas for further development of this approach are discussed; researchers should come to a general agreement on how to conduct meta-analysis. As an explicit strategy for summarizing results, meta-analysis may help clinicians and researchers better understand the findings of clinical studies.},
	language = {eng},
	number = {2},
	journal = {Annals of Internal Medicine},
	author = {L'Abbé, K. A. and Detsky, A. S. and O'Rourke, K.},
	month = aug,
	year = {1987},
	pmid = {3300460},
	keywords = {Data Collection, Decision Making, Information Systems, Outcome and Process Assessment, Health Care, Research, Research Design, Statistics as Topic},
	pages = {224--233}
}
